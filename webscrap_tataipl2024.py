# -*- coding: utf-8 -*-
"""WebScrap_TataIpl2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IZse6dzne8Wnc8EZK5ChoGBrsj78cHd2
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Send GET request to the URL
request = requests.get("https://www.iplt20.com/auction#autab4-2022")

# Parse the content with BeautifulSoup
soup = BeautifulSoup(request.content, "html.parser")

# Pretty-print the parsed HTML
print(soup.prettify())

container=soup.find("div",class_="container")
print(container)

# Correct way to search for the <a> element with multiple attributes
data = soup.find("div", class_="auction-grid-view mt-3")

print(data)

from bs4 import BeautifulSoup
import requests

# Assuming `html_content` is the HTML code provided


# List of team identifiers
teams = ["CSK", "DC", "GT", "KKR", "LSG", "MI", "PK", "RR", "RCB", "SH"]

for team in teams:
    # Find the main div for each team
    team_div = soup.find('div', class_=f"agv-main {team}")

    if team_div:
        # Get the team name
        team_name = team_div.find('div', class_="agv-team-name").text.strip()

        # Get funds remaining
        funds_remaining = team_div.find('div', class_="avg-fund-remaining").find('span', class_="fr-fund").text.strip()

        # Get overseas players and total players
        stats = team_div.find_all('li')
        overseas_players = stats[0].find('span', class_="fr-fund").text.strip()
        total_players = stats[1].find('span', class_="fr-fund").text.strip()

        # Print team information
        print(f"Team: {team_name}")
        print(f"Funds Remaining: {funds_remaining}")
        print(f"Overseas Players: {overseas_players}")
        print(f"Total Players: {total_players}")
        print("\n" + "-"*30 + "\n")

from bs4 import BeautifulSoup
import csv



# List of team identifiers
teams = ["CSK", "DC", "GT", "KKR", "LSG", "MI", "PK", "RR", "RCB", "SH"]

# Open a CSV file to store the team information
with open("team_info.csv", mode="w", newline='', encoding="utf-8") as file:
    writer = csv.writer(file)
    # Write the header
    writer.writerow(["Team", "Funds Remaining", "Overseas Players", "Total Players"])

    for team in teams:
        # Find the main div for each team
        team_div = soup.find('div', class_=f"agv-main {team}")

        if team_div:
            # Get the team name
            team_name = team_div.find('div', class_="agv-team-name").text.strip()

            # Get funds remaining
            funds_remaining = team_div.find('div', class_="avg-fund-remaining").find('span', class_="fr-fund").text.strip()

            # Get overseas players and total players
            stats = team_div.find_all('li')
            overseas_players = stats[0].find('span', class_="fr-fund").text.strip()
            total_players = stats[1].find('span', class_="fr-fund").text.strip()

            # Write the information to the CSV file
            writer.writerow([team_name, funds_remaining, overseas_players, total_players])

print("Data has been written to team_info.csv")







